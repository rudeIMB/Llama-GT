{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_parse import LlamaParse\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings.fastembed import FastEmbedEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from langchain_community.document_loaders import UnstructuredMarkdownLoader\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "#\n",
    "from groq import Groq\n",
    "from langchain_groq import ChatGroq\n",
    "#\n",
    "import joblib\n",
    "import os\n",
    "import nest_asyncio  # noqa: E402\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "llamaparse_api_key = \"llx-RGNfIFYjgNsijUxFkoqVnjDQYRqCkYbh2tYV53LVJFl85BGz\"\n",
    "groq_api_key = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_or_parse_data():\n",
    "    data_file = \"./data/parsed_data.pkl\"\n",
    "\n",
    "    if os.path.exists(data_file):\n",
    "        # Load the parsed data from the file\n",
    "        parsed_data = joblib.load(data_file)\n",
    "    else:\n",
    "        # Perform the parsing step and store the result in llama_parse_documents\n",
    "        parsingInstructionUber10k = \"\"\"Le document fourni est déposé par la BANQUE AL SALAM d'Algérie,\n",
    "\n",
    "Il contient les conditions de la banque pour l'année 2024 et les coûts de chaque service.\n",
    "\n",
    "Il contient de nombreuses tableaux.\n",
    "\n",
    "Essayez d'être précis lors de la réponse aux questions.\"\"\"\n",
    "        parser = LlamaParse(api_key=llamaparse_api_key,\n",
    "                            result_type=\"markdown\",\n",
    "                            parsing_instruction=parsingInstructionUber10k,\n",
    "                            max_timeout=5000,)\n",
    "        llama_parse_documents = parser.load_data(\"data/loi.pdf\")\n",
    "\n",
    "\n",
    "        # Save the parsed data to a file\n",
    "        print(\"Saving the parse results in .pkl format ..........\")\n",
    "        joblib.dump(llama_parse_documents, data_file)\n",
    "\n",
    "        # Set the parsed data to the variable\n",
    "        parsed_data = llama_parse_documents\n",
    "\n",
    "    return parsed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vector_database():\n",
    "    \"\"\"\n",
    "    Creates a vector database using document loaders and embeddings.\n",
    "\n",
    "    This function loads urls,\n",
    "    splits the loaded documents into chunks, transforms them into embeddings using OllamaEmbeddings,\n",
    "    and finally persists the embeddings into a Chroma vector database.\n",
    "\n",
    "    \"\"\"\n",
    "    # Call the function to either load or parse the data\n",
    "    llama_parse_documents = load_or_parse_data()\n",
    "    print(llama_parse_documents[0].text[:300])\n",
    "\n",
    "    with open('data/output.md', 'a',encoding=\"utf-8\") as f:  # Open the file in append mode ('a')\n",
    "        for doc in llama_parse_documents:\n",
    "            f.write(doc.text + '\\n')\n",
    "\n",
    "    markdown_path = \"data/output.md\"\n",
    "    loader = UnstructuredMarkdownLoader(markdown_path)\n",
    "\n",
    "   #loader = DirectoryLoader('data/', glob=\"**/*.md\", show_progress=True)\n",
    "    documents = loader.load()\n",
    "    # Split loaded documents into chunks\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=100)\n",
    "    docs = text_splitter.split_documents(documents)\n",
    "\n",
    "    #len(docs)\n",
    "    print(f\"length of documents loaded: {len(documents)}\")\n",
    "    print(f\"total number of document chunks generated :{len(docs)}\")\n",
    "    #docs[0]\n",
    "\n",
    "    # Initialize Embeddings\n",
    "    embed_model = FastEmbedEmbeddings(model_name=\"BAAI/bge-base-en-v1.5\")\n",
    "\n",
    "    # Create and persist a Chroma vector database from the chunked documents\n",
    "    vs = Chroma.from_documents(\n",
    "        documents=docs,\n",
    "        embedding=embed_model,\n",
    "        persist_directory=\"chroma_db_llamaparse1\",  # Local mode with in-memory storage only\n",
    "        collection_name=\"rag\"\n",
    "    )\n",
    "\n",
    "    #query it\n",
    "    #query = \"what is the agend of Financial Statements for 2022 ?\"\n",
    "    #found_doc = qdrant.similarity_search(query, k=3)\n",
    "    #print(found_doc[0][:100])\n",
    "    #print(qdrant.get())\n",
    "\n",
    "    print('Vector DB created successfully !')\n",
    "    return vs,embed_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#\n",
      "\n",
      "# Conditions de la Banque Al Salam - 2024\n",
      "\n",
      "# Conditions de la Banque Al Salam - 2024\n",
      "\n",
      "Le document fourni est déposé par la BANQUE AL SALAM d'Algérie, il contient les conditions de la banque pour l'année 2024 et les coûts de chaque service.\n",
      "\n",
      "# Tableau des Conditions de la Banque Al Salam - 2024\n",
      "\n",
      "|\n",
      "length of documents loaded: 1\n",
      "total number of document chunks generated :89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 5 files: 100%|██████████| 5/5 [00:00<00:00, 5005.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector DB created successfully !\n"
     ]
    }
   ],
   "source": [
    "vs,embed_model = create_vector_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_model = ChatGroq(temperature=0,\n",
    "                      model_name=\"mixtral-8x7b-32768\",\n",
    "                      api_key=groq_api_key,)\n",
    "\n",
    "vectorstore = Chroma(embedding_function=embed_model,\n",
    "                      persist_directory=\"chroma_db_llamaparse1\",\n",
    "                      collection_name=\"rag\")\n",
    "retriever=vectorstore.as_retriever(search_kwargs={'k': 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_prompt_template = \"\"\"Utilisez les éléments d'information suivants pour répondre à la question de l'utilisateur.\n",
    "Si vous ne connaissez pas la réponse, dites simplement que vous ne savez pas, n'essayez pas d'inventer une réponse.\n",
    "\n",
    "Contexte : {context}\n",
    "Question : {question}\n",
    "\n",
    "N'affichez que la réponse utile ci-dessous et rien d'autre.\n",
    "Réponse utile :\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_custom_prompt():\n",
    "    \"\"\"\n",
    "    Prompt template for QA retrieval for each vectorstore\n",
    "    \"\"\"\n",
    "    prompt = PromptTemplate(template=custom_prompt_template,\n",
    "                            input_variables=['context', 'question'])\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['context', 'question'], template=\"Utilisez les éléments d'information suivants pour répondre à la question de l'utilisateur.\\nSi vous ne connaissez pas la réponse, dites simplement que vous ne savez pas, n'essayez pas d'inventer une réponse.\\n\\nContexte : {context}\\nQuestion : {question}\\n\\nN'affichez que la réponse utile ci-dessous et rien d'autre.\\nRéponse utile :\\n\")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = set_custom_prompt()\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = RetrievalQA.from_chain_type(llm=chat_model,\n",
    "                               chain_type=\"stuff\",\n",
    "                               retriever=retriever,\n",
    "                               return_source_documents=True,\n",
    "                               chain_type_kwargs={\"prompt\": prompt})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = qa.invoke({\"query\": \"Quel est le montant de la comission Virements intra agences ASBA\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'La commission pour un virement intra agences ASBA est gratuite.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = qa.invoke({\"query\": \"Quel est le plafond hebdomadaire par type de carte CIB\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Carte Classique : Plafond hebdomadaire de 50% du revenu\\nCarte Premium : Plafond hebdomadaire de 50% à 80% du revenu\\nCarte Gold : Plafond hebdomadaire de 100% du revenu'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
